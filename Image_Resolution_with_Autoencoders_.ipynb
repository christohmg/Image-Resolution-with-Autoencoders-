{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNv7X9SyP+/aal87nzpzDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christohmg/Image-Resolution-with-Autoencoders-/blob/main/Image_Resolution_with_Autoencoders_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVIaC-oS-Qa0"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, add\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Function to load and resize images from a specified local folder\n",
        "def load_and_resize_images(folder, target_size, resize_factor):\n",
        "    images, small_images = [], []\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "            img_path = os.path.join(folder, filename)\n",
        "            with Image.open(img_path) as img:\n",
        "                img_resized = img.resize((target_size, target_size))\n",
        "                images.append(np.array(img_resized))\n",
        "\n",
        "                small_size = int(target_size * resize_factor)\n",
        "                img_small = img.resize((small_size, small_size))\n",
        "                small_images.append(np.array(img_small))\n",
        "\n",
        "    return np.array(images) / 255.0, np.array(small_images) / 255.0\n",
        "\n",
        "# Paths to your datasets, adjust as needed\n",
        "train_folder = 'data/train' # Adjust to your path\n",
        "test_folder = 'data/test' # Adjust to your path\n",
        "target_size = 256\n",
        "resize_factor = 0.25\n",
        "\n",
        "# Load and process images\n",
        "train_images, processed_train_images = load_and_resize_images(train_folder, target_size, resize_factor)\n",
        "test_images, processed_test_images = load_and_resize_images(test_folder, target_size, resize_factor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_visualize = random.randint(0, len(train_images) - 1)\n",
        "\n",
        "# Visualize the original and processed images side by side\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# Original Image\n",
        "axes[0].imshow(train_images[index_to_visualize])\n",
        "axes[0].title.set_text(\"Original Image\")\n",
        "\n",
        "# Processed Image\n",
        "axes[1].imshow(processed_train_images[index_to_visualize])\n",
        "axes[1].title.set_text(\"Processed Image\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_GsTb528-Szx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(64, 64, 3))\n",
        "\n",
        "# Encoder\n",
        "l1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "l2 = Conv2D(32, (3, 3), activation='relu', padding='same')(l1)\n",
        "l3 = MaxPooling2D((2, 2), padding='same')(l2)\n",
        "l3 = Dropout(0.3)(l3)\n",
        "l4 = Conv2D(64, (3, 3), activation='relu', padding='same')(l3)\n",
        "l5 = Conv2D(64, (3, 3), activation='relu', padding='same')(l4)\n",
        "l6 = MaxPooling2D((2, 2), padding='same')(l5)\n",
        "l7 = Conv2D(128, (3, 3), activation='relu', padding='same')(l6)\n",
        "\n",
        "# Decoder\n",
        "l8 = UpSampling2D((2, 2))(l7)\n",
        "l9 = Conv2D(64, (3, 3), activation='relu', padding='same')(l8)\n",
        "l10 = Conv2D(64, (3, 3), activation='relu', padding='same')(l9)\n",
        "# Skip connection, adjusted due to different layer sizes\n",
        "l11 = add([l5, l10])\n",
        "l12 = UpSampling2D((2, 2))(l11)\n",
        "l13 = Conv2D(32, (3, 3), activation='relu', padding='same')(l12)\n",
        "l14 = Conv2D(32, (3, 3), activation='relu', padding='same')(l13)\n",
        "# Skip connection, adjusted due to different layer sizes\n",
        "l15 = add([l14, l2])\n",
        "\n",
        "# Output layer\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(l15)\n",
        "\n",
        "# Compile the model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "# Display the summary of the model\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "cXthtsfN-jKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"autoencoder.h5\"\n",
        "checkpoint = ModelCheckpoint(model_path,\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=9,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True)\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                            patience=5,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.2,\n",
        "                                            min_lr=0.00000001)\n",
        "\n",
        "hist = autoencoder.fit(\n",
        "    processed_train_images,  # Input images\n",
        "    processed_train_images,  # Target images are the same as input\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    validation_data=(processed_test_images, processed_test_images),  # Validation data\n",
        "    callbacks=[checkpoint, earlystop, learning_rate_reduction]  # Include your callbacks here\n",
        ")"
      ],
      "metadata": {
        "id": "U6WU-MYr-nhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhance a low-resolution image from the test dataset\n",
        "image_index = random.randint(0, len(processed_test_images) - 1)\n",
        "low_res_image = processed_test_images[image_index]\n",
        "enhanced_image = autoencoder.predict(np.expand_dims(low_res_image, axis=0))[0]\n",
        "\n",
        "# Visualization of the original, low-resolution, and enhanced images\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(test_images[image_index])\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[1].imshow(low_res_image)\n",
        "axes[1].set_title(\"Low-Resolution Image\")\n",
        "axes[2].imshow(enhanced_image)\n",
        "axes[2].set_title(\"Enhanced Image\")\n",
        "for ax in axes:\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ohGuWSfN-sO8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}